{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.4 Introduction to Computation at Scale\n",
    "\n",
    "We are going to use the python [mrjob](https://github.com/Yelp/mrjob) package developed at Yelp.\n",
    "\n",
    "This package allows us to develop and test map reduce jobs locally and when ready deploy them to a hadoop cluster with hadoop streaming enabled.  We are going to use it to run jobs locally.\n",
    "\n",
    "To write a map reduce job we need to implement mapper() and reducer() functions.  The mrjob package takes care of the orchestration of the job.  Here is a first example that will count words in a file.  \n",
    "\n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'>To edit the file we are using the Jupyter Notebook Cell Magic '%%file'.  \n",
    "The file is written to the file system by the notebook when the cell is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcounter.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcounter.py \n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, value):\n",
    "        yield \"words\", len(value.split())\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key points to note:\n",
    "\n",
    "* We inherit from the class MRJob and provide at least one mapper, reducer or combiner method implementation\n",
    "* All python methods take `self` as their first argument - this is normal - not mrjob specific\n",
    "* The mappers will be sent a partition of the input data\n",
    "* The mappers must yield a key value pair - the emitted key value pairs will be sent to reducers - hash function maps the key uniquely to a node\n",
    "* The mappers and reducers are implemented as Python [generators](https://wiki.python.org/moin/Generators) - allowing the function to be used like an iterator\n",
    "* The reducers will receive the key and all the values emitted by the mappers with this key\n",
    "* The reducers must also output key and value pairs\n",
    " \n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'>The job is scheduled form the command line.  \n",
    "We can access the shell with the Jupyter Notebook line magic '!\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"wordcounter.py\", line 12, in <module>\r\n",
      "    MRWordFrequencyCount.run()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\r\n",
      "    mr_job.execute()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\r\n",
      "    super(MRJob, self).execute()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/launch.py\", line 158, in execute\r\n",
      "    self.run_job()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/launch.py\", line 224, in run_job\r\n",
      "    runner.run()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/runner.py\", line 473, in run\r\n",
      "    self._run()\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/sim.py\", line 160, in _run\r\n",
      "    _error_on_bad_paths(self.fs, self._input_paths)\r\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/mrjob/sim.py\", line 552, in _error_on_bad_paths\r\n",
      "    \"None found in %s\" % paths)\r\n",
      "ValueError: At least one valid path is required. None found in ['data/bike-item-titles-clean.txt']\r\n"
     ]
    }
   ],
   "source": [
    "! python wordcounter.py data/bike-item-titles-clean.txt > out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process runs and the output is dumped into the file out.txt.  In this case there is just a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cat out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have one pass through the file and have computed just the number of words.  We can have more elaborate jobs that compute multiple statistics.  Here we count characters, word and line count - the mapper emits three key value pairs for each line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcounter.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcounter.py \n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, value):\n",
    "        yield \"chars\", len(value)\n",
    "        yield \"words\", len(value.split())\n",
    "        yield \"lines\", 1\n",
    "        \n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/wordcounter.ubuntu.20160523.012044.403522\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/wordcounter.ubuntu.20160523.012044.403522/output...\n",
      "Removing temp directory /tmp/wordcounter.ubuntu.20160523.012044.403522...\n"
     ]
    }
   ],
   "source": [
    "! python wordcounter.py data/bike-item-titles.txt > out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"words\"\t106980\r\n",
      "\"chars\"\t714500\r\n",
      "\"lines\"\t9894\r\n"
     ]
    }
   ],
   "source": [
    "! cat out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency in Map Reduce\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>Using the word count example above can you modify the MR job to compute token frequency across the entire corpus in file `data/bike-item-titles.txt`?  Remember you can only emit (key, value) pairs from the mapper.\n",
    "\n",
    "\n",
    "**Hint** : the `/data/bike-item-titles.txt` file is quoted like a CSV file.  The easiest way to handle the CSV input presented to the mapper is to use StringIO and csv.reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some quoted text about 18\" pizzas']\n",
      "Some\n",
      "quoted\n",
      "text\n",
      "about\n",
      "18\"\n",
      "pizzas\n"
     ]
    }
   ],
   "source": [
    "import StringIO\n",
    "import csv\n",
    "\n",
    "line = '\"Some quoted text about 18\"\" pizzas\"'\n",
    "for row in csv.reader(StringIO.StringIO(line)):\n",
    "    print(row)\n",
    "    for term in row[0].split():\n",
    "        print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting term-frequency.py\n"
     ]
    }
   ],
   "source": [
    "%%file term-frequency.py \n",
    "from mrjob.job import MRJob\n",
    "import StringIO\n",
    "import csv\n",
    "\n",
    "class MRTermFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, value):\n",
    "        # << IMPLEMENT MAPPER >> CODE HERE\n",
    "        ## HIDE\n",
    "        for row in csv.reader(StringIO.StringIO(value)):\n",
    "            for term in row[1].lower().split():\n",
    "                    yield term, 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        # << IMPLEMENT REDUCER >> CODE HERE\n",
    "        ## HINT\n",
    "        yield key, sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRTermFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/term-frequency.ubuntu.20160523.012045.608427\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/term-frequency.ubuntu.20160523.012045.608427/output...\n",
      "Removing temp directory /tmp/term-frequency.ubuntu.20160523.012045.608427...\n"
     ]
    }
   ],
   "source": [
    "! python term-frequency.py data/bike-item-titles.txt > out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>Using a line magic `grep` the output file for the term bike.  \n",
    "You may want to pipe the results of `grep` to `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"inbike\"\t1\r\n",
      "\"interbike\"\t1\r\n",
      "\"lever-bike\"\t1\r\n",
      "\"light/bike\"\t1\r\n",
      "\"motor/bike\"\t1\r\n",
      "\"motorbike\"\t8\r\n",
      "\"mtb/bike\"\t1\r\n",
      "\"pbike\"\t1\r\n",
      "\"probike\"\t1\r\n",
      "\"red-bag/4-bike\"\t1\r\n"
     ]
    }
   ],
   "source": [
    "! grep 'bike' out.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'> The goal is to creat an inverted index mapping terms to rows in the file using MRJob.  The row id is in the first column of the file.  \n",
    "The input file should be `data/bike-item-titles.txt`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inverted-index.py\n"
     ]
    }
   ],
   "source": [
    "%%file inverted-index.py \n",
    "from mrjob.job import MRJob\n",
    "import StringIO\n",
    "import csv\n",
    "\n",
    "class MRInvertedIndex(MRJob):\n",
    "\n",
    "    def mapper(self, _, value):\n",
    "        # << IMPLEMENT MAPPER >> CODE HERE\n",
    "        ## HIDE\n",
    "        for row in csv.reader(StringIO.StringIO(value)):\n",
    "            id = row[0]\n",
    "            for term in row[1].lower().split():\n",
    "                    yield term, id\n",
    "                    \n",
    "    def reducer(self, key, values):\n",
    "        # << IMPLEMENT MAPPER >> CODE HERE\n",
    "        ## HIDE\n",
    "        for doc in values:\n",
    "            yield key, doc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRInvertedIndex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/inverted-index.ubuntu.20160523.012047.866588\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/inverted-index.ubuntu.20160523.012047.866588/output...\n",
      "Removing temp directory /tmp/inverted-index.ubuntu.20160523.012047.866588...\n"
     ]
    }
   ],
   "source": [
    "! python inverted-index.py data/bike-item-titles.txt > out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>`grep` the output file to find the row numbers where the item title includes the term 'unicycle'.  \n",
    "Use the UNIX command `awk`, or other UNIX command of your liking, to extract one of those lines to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"unicycle\"\t\"1883\"\n",
      "\"unicycle\"\t\"2138\"\n",
      "\"unicycle\"\t\"3748\"\n",
      "\"unicycle\"\t\"7232\"\n",
      "\"unicycle\"\t\"8777\"\n",
      "\"Electric Unicycle Hybrid Battery 800W Powered Model Q6\",\"**Shipping dates start on the 22nd of February, 2016, please contact us before placing an order!**Here it is! The Electric Urban Transporter. This is THE newest One Wheel Electric Motorcycle (UNICYCLE). Whether you’re looking to travel to work in style, grocery shop, or simply ride green through the city, the Unicycle is the way to go! This is THE greenest, easiest, and coolest way to hop around for the urban dwellers. Transform the way you think about transportation with this Self Balancing\"\n"
     ]
    }
   ],
   "source": [
    "#HIDE\n",
    "! grep '\"unicycle\"' out.txt\n",
    "! awk 'NR==2138 {print$0}' data/bike-items.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
